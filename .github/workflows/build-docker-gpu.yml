name: build-docker-images-gpus

on:
  push:
    branches: [ "main" ]
    paths-ignore: [ "*.md" ]

  pull_request:
    branches: [ "main" ]
    paths-ignore: [ "*.md" ]

  workflow_dispatch:  # Allows you to run this workflow manually from the Actions tab

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  BUILDKIT_PROGRESS: "plain"  # Full logs for CI build.
  REGISTRY_SRC: ${{ vars.REGISTRY_SRC || 'docker.io' }} # For BASE_NAMESPACE of images: where to pull base images from, docker.io or other source registry URL.
  REGISTRY_DST: ${{ vars.REGISTRY_DST || 'docker.io' }} # For tags of built images: where to push images to, docker.io or other destination registry URL.
  # DOCKER_REGISTRY_USERNAME and DOCKER_REGISTRY_PASSWORD is required for docker image push, they should be set in CI secrets.
  DOCKER_REGISTRY_USERNAME: ${{ vars.DOCKER_REGISTRY_USERNAME }}
  DOCKER_REGISTRY_PASSWORD: ${{ secrets.DOCKER_REGISTRY_PASSWORD }}
  # used to sync image to mirror registry
  DOCKER_MIRROR_REGISTRY_USERNAME: ${{ vars.DOCKER_MIRROR_REGISTRY_USERNAME }}
  DOCKER_MIRROR_REGISTRY_PASSWORD: ${{ secrets.DOCKER_MIRROR_REGISTRY_PASSWORD }}

jobs:
  # cuda docker image tags: https://hub.docker.com/r/nvidia/cuda/tags
  # latest cuda supported by torch: https://pytorch.org/get-started/locally/
  # latest cuda supported by tensorflow: https://tensorflow.google.cn/install/source?hl=en#gpu
  # latest cuda supported by paddlepadle: https://www.paddlepaddle.org.cn/
  # latest cuda supported by vllm: https://docs.vllm.ai/en/latest/getting_started/installation/gpu.html?device=cuda
  qpod_cuda_126:
    name: 'cuda_12.6,cuda'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image tmp latest docker_atom/Dockerfile --build-arg "BASE_IMG=nvidia/cuda:12.6.3-cudnn-devel-ubuntu24.04" && clear_images nvidia/cuda
          export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image tmp latest docker_base/Dockerfile --build-arg "BASE_IMG=tmp"
          build_image cuda_12.6 latest docker_cuda/nvidia-cuda.Dockerfile --build-arg "BASE_IMG=tmp"
          alias_image cuda_12.6 latest cuda latest
          push_image cuda

  # reserved for vllm: https://github.com/vllm-project/vllm/blob/main/docker/Dockerfile
  qpod_cuda_124:
    name: 'cuda_12.4'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image tmp latest docker_atom/Dockerfile --build-arg "BASE_IMG=nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04" && clear_images nvidia/cuda
          export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image tmp latest docker_base/Dockerfile --build-arg "BASE_IMG=tmp" --build-arg "REPLACE_SYS_PY=false"
          build_image cuda_12.4 latest docker_cuda/nvidia-cuda.Dockerfile --build-arg "BASE_IMG=tmp"
          push_image cuda

  # reserved for paddlepaddl 2.6: https://www.paddlepaddle.org.cn
  qpod_cuda_120:
    name: 'cuda_12.0'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image tmp latest docker_atom/Dockerfile --build-arg "BASE_IMG=nvidia/cuda:12.0.1-cudnn8-devel-ubuntu22.04" && clear_images nvidia/cuda
          export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image tmp latest docker_base/Dockerfile --build-arg "BASE_IMG=tmp"
          build_image cuda_12.0 latest docker_cuda/nvidia-cuda.Dockerfile --build-arg "BASE_IMG=tmp"
          push_image cuda

  # reserved for paddlepaddl 2.6, torch, and vllm
  qpod_cuda_118:
    name: 'cuda_11.8'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image tmp latest docker_atom/Dockerfile --build-arg "BASE_IMG=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04" && clear_images nvidia/cuda
          export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image tmp latest docker_base/Dockerfile --build-arg "BASE_IMG=tmp"
          build_image cuda_11.8 latest docker_cuda/nvidia-cuda.Dockerfile --build-arg "BASE_IMG=tmp"
          push_image cuda


  # reserved for tensorflow 1.x
  qpod_cuda_112:
    name: 'cuda_11.2'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image tmp latest docker_atom/Dockerfile --build-arg "BASE_IMG=nvidia/cuda:11.2.2-cudnn8-devel-ubuntu20.04" && clear_images nvidia/cuda
          export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image tmp latest docker_base/Dockerfile --build-arg "BASE_IMG=tmp" --build-arg "PYTHON_VERSION=3.8"
          build_image cuda_11.2 latest docker_cuda/nvidia-cuda.Dockerfile --build-arg "BASE_IMG=tmp"
          push_image cuda


  qpod_tf2:
    name: 'tf2,tf2-cuda126'
    needs: qpod_cuda_126
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image tf2-cuda126 latest docker_core/Dockerfile --build-arg "BASE_IMG=cuda_12.6"  --build-arg "ARG_PROFILE_PYTHON=tf2"
          alias_image tf2-cuda126 latest tf2 latest
          push_image

  qpod_torch_cuda126:
    name: 'torch,torch-cuda126'
    needs: qpod_cuda_126
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image torch-cuda126 latest docker_core/Dockerfile --build-arg "BASE_IMG=cuda_12.6" --build-arg "ARG_PROFILE_PYTHON=torch"
          alias_image torch-cuda126 latest torch latest
          push_image

  qpod_paddle_cuda120:
    name: 'paddle-cuda120,paddle-2.6'
    needs: qpod_cuda_120
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image paddle-cuda120 latest docker_core/Dockerfile --build-arg "BASE_IMG=cuda_12.0" --build-arg "ARG_PROFILE_PYTHON=paddle,mkl"
          alias_image paddle-cuda120 latest paddle-2.6 latest
          push_image

  qpod_paddle_cuda126:
    name: 'paddle-cuda126,paddle-3.0'
    needs: qpod_cuda_126
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh
          build_image paddle-cuda126 latest docker_core/Dockerfile --build-arg "BASE_IMG=cuda_12.6" --build-arg "ARG_PROFILE_PYTHON=paddle,mkl"
          alias_image paddle-cuda126 latest paddle-3.0 latest
          push_image


  qpod_py-nlp:
    name: 'py-nlp,py-nlp-cuda126'
    needs: qpod_cuda_126
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh && export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image py-nlp-cuda126 latest docker_core/Dockerfile --build-arg "BASE_IMG=cuda_12.6" --build-arg "ARG_PROFILE_PYTHON=datascience,mkl,torch,nlp"
          alias_image py-nlp-cuda126 latest py-nlp latest
          push_image

  qpod_py-nlp-cuda124:
    name: 'py-nlp-cuda124'
    needs: qpod_cuda_124
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh && export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image py-nlp-cuda124 latest docker_core/Dockerfile --build-arg "BASE_IMG=cuda_12.4" --build-arg "ARG_PROFILE_PYTHON=datascience,mkl,torch,nlp"
          push_image


  qpod_py-cv:
    name: 'py-cv'
    needs: qpod_cuda_126
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh && export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image py-cv   latest docker_core/Dockerfile --build-arg "BASE_IMG=cuda_12.6" --build-arg "ARG_PROFILE_PYTHON=datascience,mkl,torch,cv"
          push_image


  qpod_core-cuda:
    name: 'core-cuda,full-cuda-12.6'
    needs: qpod_cuda_126
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh && free_diskspace && export IMG_PREFIX_SRC="${IMG_PREFIX_DST}"
          build_image full-cuda-12.6 latest docker_core/Dockerfile \
            --build-arg "BASE_IMG=cuda_12.6" \
            --build-arg "ARG_PROFILE_PYTHON=base,datascience,mkl,database,nlp,cv,chem,tf2,torch" \
            --build-arg "ARG_PROFILE_R=base,datascience" \
            --build-arg "ARG_PROFILE_NODEJS=base" \
            --build-arg "ARG_PROFILE_JAVA=base,maven" \
            --build-arg "ARG_PROFILE_LATEX=base,cjk"
          alias_image full-cuda-12.6 latest core-cuda latest && push_image cuda

  qpod_nvidia-ctk:
    name: 'nvidia-ctk'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: |
          source ./tool.sh && export IMG_PREFIX_SRC="docker.io/library"
          build_image nvidia-ctk latest		docker_cuda/nvidia-ctk.Dockerfile		&& push_image


  ## Sync all images in this build (listed by "names") to mirror registry.
  sync_images:
    needs: ["qpod_core-cuda", "qpod_py-cv", "qpod_py-nlp", "qpod_torch_cuda126", "qpod_nvidia-ctk"]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - env:
          AUTH_FILE_CONTENT: ${{ secrets.AUTH_FILE_CONTENT }}
          DOCKER_MIRROR_REGISTRY: ${{ vars.DOCKER_MIRROR_REGISTRY }}
        run: |
          source ./tool.sh
          printf '%s' "$AUTH_FILE_CONTENT" > .github/workflows/auth.json && ls -alh ./.github/workflows
          printenv | grep -v 'PATH' > /tmp/docker.env && echo "REGISTRY_URL=${REGISTRY_DST}" >> /tmp/docker.env
          docker run --rm --env-file /tmp/docker.env -v $(pwd):/tmp -w /tmp ${IMG_PREFIX_DST:-qpod}/docker-kit \
            python /opt/utils/image-syncer/run_jobs.py --auth-file=/tmp/.github/workflows/auth.json \
              --workflow-file=".github/workflows/build-docker-gpu.yml"
